---
title: "How Much is Your Car Worth?"
author: "Sam Lee & Evan Miller"
format: pdf
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
library(tidyverse)

set.seed(536)

cars = read_csv("KBB.csv") %>% mutate(
  Price = log(Price),
  Sound = as.factor(Sound),
  Leather = as.factor(Leather)
)

covariates = colnames(cars)[2:length(colnames(cars))]

model.full <- lm(Price ~ Mileage*Make + ., data=cars)
model.null <- lm(Price ~ 1, data=cars)

n <- nrow(cars)

model.forward <- step(model.null, scope = list(lower = model.null, upper = model.full), 
                       direction = "forward")

model.bic <- step(model.full, direction = "both",
                       k = log(n))

plot(model.bic)
plot(model.forward)


n.cv <- 1000 #Number of CV studies we’ll run
bias <- rep(NA, n.cv) #n.cv empty biases (one for each CV)
n.test <- round(0.2*nrow(cars)) #Test 20% of the data
RPMSE <- rep(NA, n.cv)#How big my test set is
coverage <- rep(NA, n.cv)
pi_width <- rep(NA, n.cv)
for(i in 1:n.cv){
  # Choose which obs. to put in test set
  test.obs <- sample(1:nrow(cars), n.test)
  
  # Split data into test and training sets
  test.set <- cars[test.obs,]
  train.set <- cars[-test.obs,]
  
  #We need all levels of our cateogrical variables in our training set
  all.levels <- sapply(2:length(covariates), function(k){
    nrow(unique(train.set[,covariates[k]])) == nrow(unique(cars[,covariates[k]]))
  }) |> all()
  while(!all.levels){
    # Choose which obs. to put in test set
    test.obs <- sample(1:nrow(cars), n.test)
    
    # Split data into test and training sets
    test.set <- cars[test.obs,]
    train.set <- cars[-test.obs,]
    
    all.levels <- sapply(2:length(covariates), function(k){
      nrow(unique(train.set[,covariates[k]])) == nrow(unique(cars[,covariates[k]]))
    }) |> all()
  }
  
  
  # Using training data to fit a (possibly transformed) model
  train.lm <- lm(Price ~ Mileage + Model + Trim + Sound + Leather, data=train.set)
  
  # Predict test set
  test.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
  #If needed, untransform here
  
  # Calculate bias
  bias[i] <- mean(test.preds[,1]-test.set$Price)
  # Calculate RPMSE, this is left for you to figure out on your own
  
  RPMSE[i] <- (test.preds[,1]-test.set$Price)^2 %>% mean() %>% sqrt()
  
  coverage[i] <- mean((test.preds[,2] < test.set$Price) & (test.preds[,3]>test.set$Price))
  pi_width[i] <- mean(test.preds[,3] - test.preds[,2])
}

n.cv <- 1000 #Number of CV studies we’ll run
bias.2 <- rep(NA, n.cv) #n.cv empty biases (one for each CV)
RPMSE.2 <- rep(NA, n.cv)#How big my test set is
coverage.2 <- rep(NA, n.cv)
pi_width.2 <- rep(NA, n.cv)
for(i in 1:n.cv){
  # Choose which obs. to put in test set
  test.obs <- sample(1:nrow(cars), n.test)
  
  # Split data into test and training sets
  test.set <- cars[test.obs,]
  train.set <- cars[-test.obs,]
  
  #We need all levels of our cateogrical variables in our training set
  all.levels <- sapply(2:length(covariates), function(k){
    nrow(unique(train.set[,covariates[k]])) == nrow(unique(cars[,covariates[k]]))
  }) |> all()
  while(!all.levels){
    # Choose which obs. to put in test set
    test.obs <- sample(1:nrow(cars), n.test)
    
    # Split data into test and training sets
    test.set <- cars[test.obs,]
    train.set <- cars[-test.obs,]
    
    all.levels <- sapply(2:length(covariates), function(k){
      nrow(unique(train.set[,covariates[k]])) == nrow(unique(cars[,covariates[k]]))
    }) |> all()
  }
  
  # Using training data to fit a (possibly transformed) model
  train.lm <- lm(Price ~ Model + Mileage + Trim + Leather + Sound + Cruise, data=train.set)
  
  # Predict test set
  test.preds <- predict.lm(train.lm, newdata=test.set, interval="prediction")
  #If needed, untransform here
  
  # Calculate bias
  bias.2[i] <- mean(test.preds[,1]-test.set$Price)
  # Calculate RPMSE, this is left for you to figure out on your own
  
  RPMSE.2[i] <- (test.preds[,1]-test.set$Price)^2 %>% mean() %>% sqrt()
  
  coverage.2[i] <- mean((test.preds[,2] < test.set$Price) & (test.preds[,3]>test.set$Price))
  pi_width.2[i] <- mean(test.preds[,3] - test.preds[,2])
}

mean(RPMSE)
mean(RPMSE.2)

## Choose BIC because AIC RPMSE is marginally better and BIC is simpler
s <- sd(cars$Mileage, na.rm=T)
x.bar <- mean(cars$Mileage, na.rm=T)
standardize <- function(v){
  (v-mean(v, na.rm=T))/sd(v, na.rm=T)
}
cars2 <- cars %>% mutate(
  Mileage = standardize(Mileage)
)
model <- lm(Price ~ Mileage + Model + Trim + Sound + Leather, data=cars)
```

### 1

```{r echo=F}
coefficients = data.frame(
  rank = 1:length(coef(model)),
  x = sort(coef(model))
)
```

Fit a linear model on standardized covariates. Then we would look at the values of the beta coefficients. Positive significant values lead to higher resale values. Negative significant values lead to lower resale values. 

### 2

Other factors could include accident history, number of previous owners, and maintenance history.

### 3

```{r}
summary(model.full)
```

To test if amount decreased in value from additional mileage changes with the make of the car, we would test an interaction effect between mileage and make of car. To find which make holds the best value with more miles we would look at all the interaction effects and determine the most positive one. 

### 4

We would create every combination of covariates given mileage is 15,000 miles (we can do this since the rest of the covariates are discrete), and then predict the value of the car for each combination. Whichever combination has the highest predicted value would be the car that has the highest resale value at 15,000 miles.

```{r combinations}
combinations = expand.grid(
  Mileage = (15000-x.bar)/s,
  Model = unique(cars$Model),
  Trim = unique(cars$Trim),
  Leather = unique(cars$Leather),
  Sound = unique(cars$Sound)
)

y.hat <- predict.lm(model, newdata=combinations)

combinations[which(y.hat == max(y.hat, na.rm=T)),]
```

### 5

```{r}
car <- data.frame(
  Mileage = (17000-x.bar)/s,
  Model = unique(cars$Model)[6],
  Trim = unique(cars$Trim)[1],
  Leather = unique(cars$Leather)[1],
  Sound = factor(1, levels=c(0,1))
)

y.hat <- predict.lm(model, newdata=car, interval="prediction")
exp(y.hat)
```

We would create an predicted observation with the given covariates and predict the value by plugging it into the fitted model and accompany the observation with the given 95% confidence interval (an approximation for the measuring the uncertainty). 


## Methodology

### Model Evaluation

We used a Monte Carlo cross-validation techinque with a 1,000 interations on each model, evaluating the model against 20% of out-of-sample observations each iteration. 

## Results
